# LunarLanderReinforcementLearning


Se adjuntan los siguientes documentos:

rl_lunar_lander.html: Cuaderno de Jupyter Notebook (Exportado a HTML).
rl_lunar_lander.ipynb: Cuaderno de Jupyter Notebook.
rl_lunar_lander_requirements.txt : Requerimientos de entorno CONDA.
rl_lunar_lander_constants.py: Contiene constantes importantes, como nomenclaturas de archivos y constantes globales (p. ej. n_episodes).
rl_lunar_lander_generic.py: Contiene la definición de la clase base "Agent" y las rutinas de entrenamiento.
rl_lunar_lander_ERM.py: Contiene la implementación del buffer de experiencias.
rl_lunar_lander_Q.py: Contiene la implementación de DQN y DDQN.
rl_lunar_lander_DDPG.py: Contiene la implementación DDPG.
rl_lunar_lander_TD3.py: Contiene la implementación de TD3.
rl_lunar_lander_SAC.py: Contiene la implementación de SAC.
papers.zip: Papers de los algoritmos seleccionados.

Se adjuntan los videos de los algoritmos:

rl_video_td3.mp4
rl_video_sac.mp4
rl_video_dqn.mp4
rl_video_ddqn.mp4
rl_video_ddpg.mp4

Los modelos requieren un dispositivo CUDA Compatible), se deben descargar todos los archivos *.pt incluyendo el *.erm (respaldo del replay buffer, porque se puede incrementar el ciclo de entrenamiento sin necesidad de empezar desde cero).

IMPORTANTE: Todos los archivos deben estar en la misma carpeta.
